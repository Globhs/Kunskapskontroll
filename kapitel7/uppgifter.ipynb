{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f557a19c",
   "metadata": {},
   "source": [
    "## Faktafrågor\n",
    "1. Vad har ANN modellerna inspirerats av? \n",
    "\n",
    "Den har inspirerats av hur människo hjärnan tänker.\n",
    "\n",
    "2. Vad refererar \"djup\" till i begreppet \"djupinlärning\"?\n",
    "\n",
    "Med djup menas att det finns flera dolda lager, lagrerna lär sig olika saker vissa mer fundementala än andra.\n",
    "\n",
    "3. Förklara vad som händer i figur 7.2, 7.3, figur 7.4 och figur 7.5. Varför används aktiveringsfunktioner? \n",
    "I 7.2 visas det hur två vikter från input lagret läggs till och multipliceras i output lagret.\n",
    "I 7.3 Visas det ett mer komplext exempel på ett neuralt nätverk men den skiljer sig fortfarande inte ifrån en vanligt linjär regression, då det inte finns en aktiveringsfunktion.\n",
    "I 7.4 I denna figur Visar den Logistic/sigmoid och RELU två vanligas aktiverings funktioner som används vid olika tillfällen beroende på vilken output man ska få ut.\n",
    "I 7.5 Visas en figur som liknar figur 7.2 fast i denna finns det också en aktiverings funktion i output-lagret vilket gör modellen icke-linjär.\n",
    "\n",
    "4. Har neurala nätverk få eller många parametrar? \n",
    "\n",
    "Dem har oftast många parametrar.\n",
    "\n",
    "5. Förklara intuitivt hur *dropout*-regularisering fungerar. \n",
    "\n",
    "Dropout-regulasering droppar noder slumpmässigt för att motverka överanpassning och får noderna i modellen att bli mindre beroende av varandra. \n",
    "\n",
    "## Resonemangfrågor\n",
    "6. Din kollega ber dig förklara tabell 7.1 och tabell 7.2. Gör det!\n",
    "I figur 7.1 visas ett Artificiellt Neuralt Nätverk (ANN), det är en modell baserad op hur den mänskliga hjärnan tar in information. Modellen har 4 input-dnoder där man matar in sin data. Därefter passerar datan genom två dålda lage (hidden layers), där varje nod får vikter och en aktiveringsfunktion på inputen. Modellen lär sig att juster vikterna för att minimera fel och validerar sedan resultaten mot validerings data. På så sätt kan nätverket förbättra sig genom varje gång datan körs igenom. Fler hidden layer med komplex modell.\n",
    "I Figur 7.2 visas det hur två vikter från input lagret läggs till och multipliceras i output lagret.\n",
    "7. Experimentera med neurala nätverk på följande länk: \n",
    "[https://playground.tensorflow.org/](https://playground.tensorflow.org/)\n",
    "\n",
    "8. Förklara översiktligt hur *backpropagation* fungerar. Använd figur 7.7 till din hjälp. \n",
    "\n",
    "Backpropagation möjliggör att modellen kan tränas om beroende på felen som gjorts under träningen innan. Vikter justeras bakåt genom träningen för att modellen ska lära sig av sina misstag.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94757fe6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
