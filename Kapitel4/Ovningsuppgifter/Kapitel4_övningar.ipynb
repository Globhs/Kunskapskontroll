{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb5a2702-6e92-4947-9b19-9130a07e3baf",
   "metadata": {},
   "source": [
    "# Kapitel 4 Övningar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f5bc41-3fc7-4b2b-b074-5166575d2379",
   "metadata": {},
   "source": [
    "## Fakta frågor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33959d8-3f13-4dcb-8655-d34f23f620a2",
   "metadata": {},
   "source": [
    "### 1. \n",
    "Klassificeringsporblem handlar om att prediktera kategorisk data där datan kan vara anta olika klasser, tillexempel prediktera ifall en patient kommer överleva eller inte, eller prediktera vad för djur som är på en bild."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ecace-5f8b-4d49-935a-dea5d13b6f02",
   "metadata": {},
   "source": [
    "### 2. \n",
    "OvO och OvR är algoritmer som gör att binära klassificeringsmodeller kan hantera multiklass klassificering. \n",
    "Dem fungerar lite olika, OvO kör en klass mot en annan klass tills alla klasser mött varandra, denna är bättre när klasserna är svåra att spearera men tar också längre tid. \n",
    "OvR kör en klass mot alla dem andra klasserna, för varenda klass. OvR är snabbare men kan lätt få konstigt svar ifall datan är obalanserad.\n",
    "\n",
    "\n",
    "OvR = \n",
    "\n",
    "Modell 1: A vs (B, C)\n",
    "\n",
    "Modell 2: B vs (A, C)\n",
    "\n",
    "Modell 3: C vs (A, B)\n",
    "\n",
    "\n",
    "OvO = \n",
    "\n",
    "Modell 1: A vs B\n",
    "\n",
    "Modell 2: A vs C\n",
    "\n",
    "Modell 3: B vs C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef9448c-d20d-4e5b-8397-035e08163b0e",
   "metadata": {},
   "source": [
    "### 3.\n",
    "### a.\n",
    "Confusion matrix är en matris för att visualisera hur väl en modell preseterar genom att jämnföra predikterade mot faktiska värden.\n",
    "### b.\n",
    "Accuracy är ett mått på hur stor andel av alla observationer som klassificerats rätt.\n",
    "### c.\n",
    "Precision är ett utvärderingsmått som berätta hur stor andel av dem positiva prediktionerna som faktist är positiva\n",
    "### d.\n",
    "Recall är ett utvärderingsmått som berättar hur stor andel faktiskt positiva fallen som modellen hittar.\n",
    "### e.\n",
    "F1-score är ett utvärderingsmått som visar det harmoniska medelvärdet för precision och recall.\n",
    "### f.\n",
    "Den är lik F1-score men istället för precision och trcall visualiserar den sambandet mellan TPR (True Positive Rate) och FPR (False Positive Rate). TPR är en annan benämning för TPR. Skillnaden mellan ROC-Kurvan och F1-score är då att ROC-kurvan ger en helhetsbild av modellens beteende över alla möjliga trösklar. Den används ofta för att jämföra modeller oberoende av vald cut-off.\n",
    "F1-score ger en specifik utvärdering vid en viss tröskel, och är extra användbar när man har obalanserade klasser och vill balansera mellan att inte missa positiva (recall) och inte få för många falsklarm (precision). 1 = perfekt, 0,75 = slumpmässigt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96238efd-8b93-415e-b31b-a16febb22118",
   "metadata": {},
   "source": [
    "### 4.\n",
    "Precision-recall tradeoff handlar om balansen mellan recall och precision. Tex på ett sjukhus ska man klasificera ifall folk är sjuka eller inte. Om man har högt Recall så klassificeras näst intill alla som sjuka vilket betyder att alla faktiskt sjuka kommer få hjälp, men många av dem som inte är sjuka kommer också klassificeras som sjuka vilket tyder på dålig preccision. Om man då tänker på livshotande sjukdomar så är det kritiskt att dem som faktist inte är sjuka men klassificerades som det inte tar upp en livshotande patients plats. Därmed behöver vi hitta den balans mellan precision och recall som fungerar bäst."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773be6bc-3394-45d3-95f6-fa352b8b0e98",
   "metadata": {},
   "source": [
    "### 5. \n",
    "### a.\n",
    "Logistisk regression är en klassificeringsmodell, det är en vinär klasssificerar och modellen utför klassificering genom att estimera sannolikheten för att en datapunkt tillhör en klass. Om sannolikheten är 50% eller mer så kommer modellen att prediktera datapunkten den klassen. Om datapunkten är lägre än 50% så kommer den tilldela datapunkten den andra klassen alltså den negativa klassen \"0\".\n",
    "### b.\n",
    "Support vector machines försöker hitta en så bred väg som möjligt mellan observationer från olika klasser för att dela upp klasserna så gott som möjligt.\n",
    "### c.\n",
    "Beslutsträd eller decisiontree fungerar både på regression problem samt klassificeringsproblem. Det delar upp datan i två delar tills att den nått max depthen, när modellen delar så delar den datan så att det ska bli så ren nod som möjligt alltså så lite fel som möjligt. Ju längre ner i trädet desto mindre blir värdet på gini-koefficienten.\n",
    "### d.\n",
    "När man använder ensemble learning i klassificeringsproblem så finns det något som heter voting classifier det finns soft voting(Varje modell ger en sannolikhet och ett genomsnitt beräknas, den klass som fick högst genomsnittlig sannolikhet väljs) och hard voting(majoritets röstning mellan modellerna). \n",
    "### e.\n",
    "Randomforest är ett enseble av beslutsträd som oftast skapas genom bagging, ibland pasting.\n",
    "### f. \n",
    "Extra tree är en varation av RandomForest fast den har högre bias. Den tar inte bara en slumpmässig grupp av features genom bagging utan också väljer en slumpmässigt värde på tröskelvärde för varje nod/split, randomforrest väljer det mest optimala tröskelvärdet för varje nod/split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8604f64-334f-474b-9199-f3bcdcb5bfd8",
   "metadata": {},
   "source": [
    "## 6.\n",
    "att kolla feature-importance innebär att vi tittar vilka variabler modellen anser vara mest relevanta för att göra dem bästa prediktionerna."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8912ce34-270e-4171-b620-7951685dd168",
   "metadata": {},
   "source": [
    "# Koduppgifter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95f0f05-c57c-4799-b082-ddd84acaa084",
   "metadata": {},
   "source": [
    "### 9.\n",
    "Koden nedan predikterar y_true mot y_pred och utvärderar i precision recall och f1_score för varje class. Längre ner utvärderar den för all data, accuracy = predikterar hur många procent av prediktionerna som var rätt\n",
    "\n",
    "Macro avg = genomsnittet  av precision, recall och f1_score för alla klasser\n",
    "\n",
    "weighted avg = (man tar f1-score x support för varjeklass) / (totalt antal support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd60de6b-79f6-4540-9611-016ce5a4e87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.50      1.00      0.67         1\n",
      "     class 1       0.00      0.00      0.00         1\n",
      "     class 2       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.50      0.56      0.49         5\n",
      "weighted avg       0.70      0.60      0.61         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = [0, 1, 2, 2, 2]\n",
    "y_pred = [0, 0, 2, 2, 1]\n",
    "target_names = [\"class 0\", \"class 1\", \"class 2\"]\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbad6c9b-ae48-4e46-ac9f-8bd86c9b6eec",
   "metadata": {},
   "source": [
    "### 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d781db3-5c45-41f8-a952-9601403afa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
      "0                0.38             0.53               2                   157   \n",
      "1                0.80             0.86               5                   262   \n",
      "2                0.11             0.88               7                   272   \n",
      "3                0.72             0.87               5                   223   \n",
      "4                0.37             0.52               2                   159   \n",
      "\n",
      "   time_spend_company  Work_accident  left  promotion_last_5years  \\\n",
      "0                   3              0     1                      0   \n",
      "1                   6              0     1                      0   \n",
      "2                   4              0     1                      0   \n",
      "3                   5              0     1                      0   \n",
      "4                   3              0     1                      0   \n",
      "\n",
      "   Emp_Id_IND010  Emp_Id_IND01003  ...  Department_accounting  Department_hr  \\\n",
      "0          False            False  ...                  False          False   \n",
      "1          False            False  ...                  False          False   \n",
      "2          False            False  ...                  False          False   \n",
      "3          False            False  ...                  False          False   \n",
      "4          False            False  ...                  False          False   \n",
      "\n",
      "   Department_management  Department_marketing  Department_product_mng  \\\n",
      "0                  False                 False                   False   \n",
      "1                  False                 False                   False   \n",
      "2                  False                 False                   False   \n",
      "3                  False                 False                   False   \n",
      "4                  False                 False                   False   \n",
      "\n",
      "   Department_sales  Department_support  Department_technical  salary_low  \\\n",
      "0              True               False                 False        True   \n",
      "1              True               False                 False       False   \n",
      "2              True               False                 False       False   \n",
      "3              True               False                 False        True   \n",
      "4              True               False                 False        True   \n",
      "\n",
      "   salary_medium  \n",
      "0          False  \n",
      "1           True  \n",
      "2           True  \n",
      "3          False  \n",
      "4          False  \n",
      "\n",
      "[5 rows x 15017 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "df = pd.read_excel(\"hr_employee_data(1).xlsx\")\n",
    "df.dropna(how=\"any\", inplace=True)\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fd68c90-96cb-4b0b-b0a8-3b720aa28ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_emp = df.drop(columns=[\"left\"]) \n",
    "y_emp = df[\"left\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44f4a212-71e2-42ad-a77b-4fb07e397eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_emp, y_emp, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=42)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=10, n_jobs=-1)\n",
    "\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "log_pred = log_reg.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70cc68b3-9947-4a7c-89fc-caa616bafa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression RMSE:  0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"LogisticRegression RMSE: \", root_mean_squared_error(y_val, log_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee2555-ce49-4bdd-83c6-af31a61266d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
